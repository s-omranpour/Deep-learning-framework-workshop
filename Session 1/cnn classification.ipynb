{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Readings\n",
    "\n",
    "modules, losses, activations, etc. :\n",
    " - https://pytorch.org/docs/stable/nn.html\n",
    " \n",
    "optimizers and schedulers:\n",
    " - https://pytorch.org/docs/stable/optim.html\n",
    " \n",
    "examples:\n",
    " - https://github.com/pytorch/examples/blob/master/vae/main.py\n",
    " - https://github.com/pytorch/examples/blob/master/mnist/main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "from Models.cnn_classifier import Classifier\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier(\n",
      "  (net): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
      "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.1, inplace=False)\n",
      "    (4): Conv2d(8, 16, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
      "    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): Dropout(p=0.2, inplace=False)\n",
      "    (8): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU()\n",
      "    (11): Dropout(p=0.3, inplace=False)\n",
      "    (12): Flatten()\n",
      "    (13): Linear(in_features=1568, out_features=10, bias=True)\n",
      "    (14): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (15): Softmax(dim=None)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cls = Classifier(input_size=28, num_classes=10, in_channel=1,\n",
    "                 out_channels=[8,16,32], kernels=[5,5,3],\n",
    "                 strides=[2,2,1], dropouts=[.1,.2,.3])\n",
    "\n",
    "# cls.cuda()\n",
    "print(cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23886"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.get_n_params(cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = MNIST(root='data', train=False, transform=ToTensor(), download=True)\n",
    "len(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7000, 3000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, test_data = random_split(mnist, [7000,3000])\n",
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(cls.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cfdaf1d72014944bbdbe4203cc5a554",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 train_loss:2.1844346371563996 train_acc:0.4583333333333333\n",
      "val_loss:2.0741699604277914 val_acc:0.75\n",
      "\n",
      "2 train_loss:2.024366061253981 train_acc:0.7083333333333334\n",
      "val_loss:1.987453359238645 val_acc:0.8035714285714286\n",
      "\n",
      "3 train_loss:1.9679070884531193 train_acc:0.6666666666666666\n",
      "val_loss:1.946497729484071 val_acc:0.7857142857142857\n",
      "\n",
      "4 train_loss:1.9316285978664052 train_acc:0.8333333333333334\n",
      "val_loss:1.9217698117519946 val_acc:0.8214285714285714\n",
      "\n",
      "5 train_loss:1.90823885419152 train_acc:0.8333333333333334\n",
      "val_loss:1.8984166485198 val_acc:0.875\n",
      "\n",
      "6 train_loss:1.8880571777170354 train_acc:0.875\n",
      "val_loss:1.882584105146692 val_acc:0.8214285714285714\n",
      "\n",
      "7 train_loss:1.8695084127512844 train_acc:0.875\n",
      "val_loss:1.8619685299853062 val_acc:0.8571428571428571\n",
      "\n",
      "8 train_loss:1.8554998517036438 train_acc:0.7916666666666666\n",
      "val_loss:1.8480621677763918 val_acc:0.8392857142857143\n",
      "\n",
      "9 train_loss:1.8445734869350086 train_acc:0.7083333333333334\n",
      "val_loss:1.84285694994825 val_acc:0.875\n",
      "\n",
      "10 train_loss:1.8332321654666555 train_acc:0.9583333333333334\n",
      "val_loss:1.8289078245771693 val_acc:0.9107142857142857\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "utils.train(cls, train_loader, test_loader, criterion, optimizer, device='cpu', epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
